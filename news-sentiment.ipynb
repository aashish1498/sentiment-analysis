{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71411b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from article_retriever import *\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    sentences = [preprocess_sentence(sentence) for sentence in sentences]\n",
    "    return sentences\n",
    "    # return '. '.join(sentences)\n",
    "\n",
    "\n",
    "def preprocess_sentence(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = tokenize.word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "def get_vader_polarity(raw_text):\n",
    "    processed_text = preprocess_text(raw_text)\n",
    "    score = sia.polarity_scores('. '.join(processed_text))\n",
    "    return score['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url = \"https://www.bbc.co.uk/news/topics/cwlw3xz01lxt\" # transgender people\n",
    "topic_url = \"https://www.bbc.co.uk/news/topics/cx2pk70323et\" # upifting\n",
    "topic_url = \"https://www.thepinknews.com/identity/trans\"\n",
    "\n",
    "url_list = get_articles_for_topic(topic_url)\n",
    "print(url_list)\n",
    "\n",
    "full_polarity_list = []\n",
    "for url in url_list:\n",
    "    [header, my_text] = get_info_from_article(url)\n",
    "    my_polarity = get_vader_polarity(my_text)\n",
    "    full_polarity_list.append(my_polarity)\n",
    "    print(header)\n",
    "    print(my_polarity)\n",
    "\n",
    "print(\"Average polarity: \")\n",
    "print(np.mean(full_polarity_list))\n",
    "# TODO: consider wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram on x\n",
    "x = full_polarity_list\n",
    "plt.hist(x, bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = full_polarity_list\n",
    "n = int(len(my_list) ** 0.5)\n",
    "my_matrix = [my_list[i:i+n] for i in range(0, len(my_list), n)]\n",
    "# create the heatmap using seaborn\n",
    "sns.heatmap(my_matrix, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_url = \"https://www.thepinknews.com/2023/03/10/coming-out-trans-non-binary-later-life-suzie-eddie-izzard/\"\n",
    "text = get_info_from_article(pink_url)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09864c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = preprocess_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sia.polarity_scores('. '.join(processed_text))\n",
    "polarity = score['compound']\n",
    "print(polarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab0de5f2c42c334a270ce520738908c8f1964f7214e5cf9b2725bca46514c63e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
